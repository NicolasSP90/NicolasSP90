# Quem sou eu

Meu nome é Nícolas Sartor Parisotto. Tenho 13 anos de experiência em desenvolvimento de tecnologias e projetos e estou atualmente dedicando meu tempo para me desenvolver nas áreas de Data Science, Data Engineering e Software Development. Estou em busca de vagas de entrada/júnior ou mesmo estágio.

Meu currículo pode ser acessado <a href="https://portfolio-curriculo-five.vercel.app/">aqui</a>

[![GitHub](https://img.shields.io/badge/GitHub-000?style=border_radius&logo=Github&logoColor=blue)](https://github.com/NicolasSP90)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-000?style=border_radius&logo=linkedin&logoColor=blue)](https://www.linkedin.com/in/nicolasparisotto/)
[![E-mail](https://img.shields.io/badge/-Email-000?style=border_radius&logo=microsoft-outlook&logoColor=blue)](mailto:nicolassp90@hotmail.com)

---

# Tecnologias

![Python](https://img.shields.io/badge/Python-000?style=border_radius&logo=python&logoColor=blue)
![pyenv](https://img.shields.io/badge/pyenv-000?style=border_radius)
![poetry](https://img.shields.io/badge/poetry-000?style=border_radius)

![SQL](https://img.shields.io/badge/SQL-000?style=border_radius&logo=sql)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-000?style=border_radius&logo=postgresql&logoColor=blue) 

![HTML5](https://img.shields.io/badge/HTML5-black?style=borde_radius&logo=html5&logoColor=blue) 
![CSS3](https://img.shields.io/badge/CSS3-black?style=borde_radius&logo=css3&logoColor=blue)
![JavaScript](https://img.shields.io/badge/JavaScript-black?style=border_radius&logo=javascript&logoColor=blue)

![VSCode](https://img.shields.io/badge/VSCode-black?style=border_radius)
![PyCharm](https://img.shields.io/badge/PyCharm-black?style=border_radius)
![Databricks](https://img.shields.io/badge/DataBricks-black?style=border_radius&logo=databricks&logoColor=blue)
![Git](https://img.shields.io/badge/Git-black?style=border_radius&logo=git&logoColor=blue)
![GitHub](https://img.shields.io/badge/GitHub-black?style=border_radius&logo=github&logoColor=blue)
![draw.io](https://img.shields.io/badge/draw.io-000?styleborder_radius&logo=diagrams&logoColor=blue)

![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=NicolasSP90&layout=compact&theme=github_dark)

---

# Projetos e Repositórios

## [Big Data - Cadastro Rural](https://github.com/NicolasSP90/big_data_cadastro_ambiente_rural)
Para o sexto e último projeto da trilha de Engenharia de Dados do Santander Coders + AdaTech, tivemos que comparar as solicitações entre banco distribuído e banco centralizado. A fim de utilizar tecnologias diferentes, foi configurado um ambiente Docker com Spark, Delta Tables e Hive para a solução de banco distribuído e adicionado Pandas e Bibliotecas de conexão com banco de dados MySQL para conexão com banco externo. Para a solução distribuída foi criada uma pipeline de um processo de ETL com arquitetura Medallion e verificados os tempos de querys para duas situações: As Delta Tables da camada Silver; As tabelas salvas e gerenciadas com o Hive. Após isso foi criado um ambiente para as querys do banco de dados MySQL externo e utilizado Pandas para responder conexão e verificação dos tempos de resposta.

## [Analytics Engineering](https://github.com/NicolasSP90/Analytics_Engineering_AirBnB)
Para o quinto projeto da trilha de Engenharia de Dados do Santander Coders + AdaTech, tivemos que criar um pipeline de um processo de ETL e adicionar Great Expectations para verificar e validar a qualidade dos dados. O projeto foi realizado inteiramente no Databricks a partir de dados disponibilizados pelo AirBnB, utilizando notebooks para armazenar funções e objetos, um notebook para as entrypoints e um notebook com o script de utilização. O projeto contou arquitetura Medallion, Delta Tables tabelas na camada gold utilizando Hive para consultas.

## [Data Pipeline](https://github.com/NicolasSP90/Projeto_DataPipeline)
Para o quarto projeto da trilha de Engenharia de Dados do Santander Coders + AdaTech, tivemos que criar um pipeline de um processo de ETL. O projeto foi iniciado em ambiente local para realização de alguns testes e então o projeto foi migrado para o *Databricks* para real aplicação. O processo de extração foi realizado a partir de API e tanto os dados brutos como transformados foram salvos em arquivos *.parquet*, sendo os dados transformados também disponibilizados em formato *delta* e em banco de dados para ser acessado diretamente. Finalmente, o processo contou com a elaboração de tabelas para resposta a algumas perguntas de negócio e disponibilização dessas tabelas em bando de dados. O projeto também contou com automação para que os dados pudesses ser extraídos e transformados em intervalos específicos de tempo.

## [Data Quality](https://github.com/NicolasSP90/Projeto_Data_Quality)
Para o terceiro projeto da trilha de Engenharia de Dados do Santander Coders + AdaTech, tivemos que aplicar conceitos de POO para criar uma classe de Data Quality. A classe deve gerar um relatório com estatística descritiva, dispersão e mais informações sobre uma base de dados em *.csv*. O objetivo é ter informações o suficiente para gerar insights de uma maneira rápida e facilitar as posteriores etapas de limpeza de dados e análise exploratória. Além disso, o projeto tinha como objetivo o trabalho colaborativo utilizando o github para, em grupo, desenvolver a aplicação.

## [POO CRUD](https://github.com/NicolasSP90/POO_CRUD_SantanderCoders2024)
Para o segundo projeto da trilha de Engenharia de Dados do Santander Coders + AdaTech, tivemos que aplicar conceitos de POO para criar um CRUD (Create, Read, Update Delete). O objetivo é a manipulaçao de objetos e foi proposto que fosse trabalhado com dicionários. Utilize dessas definições para simular um sistema destinados a Instituições de saúde, com registros de Instituições, Consultas, Médicos e Pacientes (todos fictícios). Também foi criada uma interface para interação com o usuário e um Gerenciado para fazer integração entre Interface, Objetos e arquivos .json. A escolha de arquivos .json se deu porque não poderíamos usar bibliotecas não nativas e porque quis simular a aplicação de um banco de dados.

## [Algorítmo KNN](https://github.com/NicolasSP90/KNN_SantanderCoders2024)
Para o primeiro pprojeto da trilha de Engenharia de Dados do Santander Coders + AdaTech, tivemos que aplicar algumas definições básicas de python e lógica de programação para criar um algorítmo de KNN sem o auxílio de bibliotecas externas. O KNN (K-Nearest Neighbors) é um modelo supervisionado de Machine Learning que pode ser utilizado tanto para classificação quanto para regressão. O desafio envolve criar e utilizar o modelo para corretamente classificar o perfil de investidores baseado nas carteiras de investimento.

## [Classificação de Objetos](https://github.com/NicolasSP90/CNN_HortiFruit)
Projeto de classificação de imagens. O intuito do projeto é aplicar uma Rede Neural Convolucional para classificar objetos. Nesse caso o tema de estudo eram hortifrutas para uma rede de supermercados. O projeto utiliza bibliotecas redes PyTorch como base para a rede neural e Gradio para testar o resultado. Também foi criada uma aplicação no [HuggingFace](https://huggingface.co/spaces/NicolasSP90/Project_6_CNN_Image_Classifier/tree/main) do projeto.

## [Segmentação de Clientes](https://github.com/NicolasSP90/Projeto_PCA_KMeans)
Projeto de segmentação de clientes. O intuito do projeto é aplicar tecnologias e técnicas para segmentar clientes através de dados de pesquisa realizada junto dos mesmos. O projeto utiliza algorítmos de PCA para diminuição de dimensionalidade e KMeans para segmentação dos clientes com a biblioteca scikit-learn.

## [Predição de Churn](https://github.com/NicolasSP90/Predicao_Churn)
Projeto de Prediçao de Churn. O intuito do projeto é aplicar tecnologias e técnias para prever o Churn dos funcionários d euma empresa, baseado nos dados do disponíveis. O projeto é baseado em modelos de classificação da biblioteca scikit-learn, xgboost e lightgbm e a comaração das métricas entre eles.

## [Predição de Preços](https://github.com/NicolasSP90/Predicao_Precos)
Projeto de Prediçao de Preços. O intuito do projeto é aplicar tecnologias e técnias para prever o resultado do valor de seguro de vida, baseado nos dados do usuário. O projeto é baseado em modelos de regressão linear e compara as métricas com árvore de decisão.

## [EDA - ENEM 2023](https://github.com/NicolasSP90/EDA_ENEM2023)
Projeto de Análise Exploratoria de Dados (EDA). A base de dados é referente ao ENEM de 2023, disponibilizada publicamente. O intuito do projeto é aplicar tecnologias e técnicas aprendidas em um projeto com dados reais. A partir disso, obter insights sobre os dados apresentados. 

## [Challenge Alura - Decodificador](https://github.com/NicolasSP90/ChallengeDecodificador)
O início da trilha de Back-End do programa Oracle Next Education traz conceitos de lógica de programação e desenvolvimento web em HTML e CSS. Esse projeto é a última etapa do início do curso, e possui algumas regras específicas que deveriam ser seguidas, mas com a obrigatoriedade de personalização pessoal. O deploy pode ser visualizado no <a href="https://nicolassp90.github.io/ChallengeDecodificador/">GitHub Pages</a> ou no <a href="https://alura-challenge-decodificador-seven.vercel.app/">Vercel</a>.

## [OP_Pages](https://github.com/NicolasSP90/OP_Pages)
Projeto pessoal. Desde os meus 15 anos eu leio o Mangá One Piece. Decidi automatizar a checagem e download dos últimos capítulos. Para isso criei um scrapper para perder menos tempo fazendo essa organização.

## [DiscordBot - The Firemind](https://github.com/NicolasSP90/DiscordBot---The-Firemind)
Projeto Pessoal. Criei um servidor Discord para a campanha que mestro e decidi adicionar algumas apllicações para os jogadores. Coloquei algumas integrações e bots para o jogo e decidi criar um Bot a partir da API da OpenAI para caso algo precise ser criado na hora, poderia utilizar o bot e a interação com os jogadores. Esse é o projeto do Bot e o nome é em referência a um personagem do cardgame Magic the Gathering.

## [Fiasco2DnD](https://github.com/NicolasSP90/Fiasco2DnD)
Projeto Pessoal. Jogo e Mestro campanhas de RPG. Normalmente o início das campanhas é necessário fazer uma gambiarra narrativa para que os personagens possuam um motivo para continuarem como grupo. Pensando em deixar essa situação mais flúida, fiz uma pequena automação para gerar conexões aleatórias entre os jogadores. A adaptação é baseada em um RPG de nome "Fiasco".

---